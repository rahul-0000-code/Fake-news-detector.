{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "import random\n",
    "\n",
    "nlp = spacy.load('el_core_news_md')\n",
    "df = pd.read_csv('../data/greek_fake_news.csv')\n",
    "df.replace(to_replace='[\\n\\r\\t]', value=' ', regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(train_data, limit=0, split=0.8):\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[-limit:]\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{\"REAL\": not bool(y), \"FAKE\": bool(y)} for y in labels]\n",
    "    split = int(len(train_data) * split)\n",
    "    \n",
    "    return (texts[:split], cats[:split]), (texts[split:], cats[split:])\n",
    "\n",
    "def evaluate(tokenizer, textcat, texts, cats):\n",
    "    docs = (tokenizer(text) for text in texts)\n",
    "    tp = 0.0  # True positives\n",
    "    fp = 1e-8  # False positives\n",
    "    fn = 1e-8  # False negatives\n",
    "    tn = 0.0  # True negatives\n",
    "    for i, doc in enumerate(textcat.pipe(docs)):\n",
    "        gold = cats[i]\n",
    "        for label, score in doc.cats.items():\n",
    "            if label not in gold:\n",
    "                continue\n",
    "            if label == \"FAKE\":\n",
    "                continue\n",
    "            if score >= 0.5 and gold[label] >= 0.5:\n",
    "                tp += 1.0\n",
    "            elif score >= 0.5 and gold[label] < 0.5:\n",
    "                fp += 1.0\n",
    "            elif score < 0.5 and gold[label] < 0.5:\n",
    "                tn += 1\n",
    "            elif score < 0.5 and gold[label] >= 0.5:\n",
    "                fn += 1\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    if (precision + recall) == 0:\n",
    "        f_score = 0.0\n",
    "    else:\n",
    "        f_score = 2 * (precision * recall) / (precision + recall)\n",
    "    return {\"textcat_p\": precision, \"textcat_r\": recall, \"textcat_f\": f_score}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   title    100 non-null    object\n",
      " 1   text     100 non-null    object\n",
      " 2   source   100 non-null    object\n",
      " 3   url      100 non-null    object\n",
      " 4   is_fake  100 non-null    int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tagger', 'parser', 'ner', 'textcat']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat=nlp.create_pipe( \"textcat\", config={\"exclusive_classes\": True, \"architecture\": \"simple_cnn\"})\n",
    "nlp.add_pipe(textcat, last=True)\n",
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.add_label(\"REAL\")\n",
    "textcat.add_label(\"FAKE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tuples'] = df.apply(lambda row: (row['text'], row['is_fake']), axis=1)\n",
    "train = df['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(train, split=0.9)\n",
    "\n",
    "train_data = list(zip(train_texts,[{'cats': cats} for cats in train_cats]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "LOSS \t  P  \t  R  \t  F  \n",
      "0.669\t0.714\t1.000\t0.833\n",
      "0.346\t0.714\t1.000\t0.833\n",
      "0.382\t0.833\t1.000\t0.909\n",
      "0.378\t0.714\t1.000\t0.833\n",
      "0.120\t0.833\t1.000\t0.909\n",
      "0.068\t0.833\t1.000\t0.909\n",
      "0.025\t0.714\t1.000\t0.833\n",
      "0.004\t0.714\t1.000\t0.833\n",
      "0.001\t0.833\t1.000\t0.909\n",
      "0.004\t0.714\t1.000\t0.833\n",
      "0.023\t0.714\t1.000\t0.833\n",
      "0.005\t0.714\t1.000\t0.833\n",
      "0.001\t0.714\t1.000\t0.833\n",
      "0.003\t0.714\t1.000\t0.833\n",
      "0.003\t0.714\t1.000\t0.833\n",
      "0.016\t0.714\t1.000\t0.833\n",
      "0.004\t0.714\t1.000\t0.833\n",
      "0.024\t0.714\t1.000\t0.833\n",
      "0.005\t0.714\t1.000\t0.833\n",
      "0.000\t0.833\t1.000\t0.909\n"
     ]
    }
   ],
   "source": [
    "n_iter = 20\n",
    "# Disabling other components\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "\n",
    "    print(\"Training the model...\")\n",
    "    print('{:^5}\\t{:^5}\\t{:^5}\\t{:^5}'.format('LOSS', 'P', 'R', 'F'))\n",
    "\n",
    "    # Performing training\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                       losses=losses)\n",
    "\n",
    "      # Calling the evaluate() function and printing the scores\n",
    "        with textcat.model.use_params(optimizer.averages):\n",
    "            scores = evaluate(nlp.tokenizer, textcat, dev_texts, dev_cats)\n",
    "        print('{0:.3f}\\t{1:.3f}\\t{2:.3f}\\t{3:.3f}'  \n",
    "              .format(losses['textcat'], scores['textcat_p'],\n",
    "                      scores['textcat_r'], scores['textcat_f']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'REAL': 1.9296246378530668e-08, 'FAKE': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = '''\n",
    "Η Κυβερνητική ανακοίνωση να μειώσει τα Τακτικά Χειρουργεία εως 80% ΣΚΟΤΩΝΕΙ περισσότερους Ελληνες Πολίτες…ειναι η Κυβέρνηση που νοιάζεται για σένα. Χιλιάδες συμπολίτες μας περιμένουν να νοσηλευτούν να θεραπευτούν και να χειρουργηθούν απο τις γνωστές σοβαρές ασθένειες …και δεν μπορουν να περιμένουν.\n",
    "Οσοι δεν εχουν την Οικονομική δυνατότητα να πάνε στον Ιδιωτικό τομεα το Κράτος του ΜΗΤΣΟΤΑΚΗ-ΧΑΡΔΑΛΙΑ δεν νοιάζεται..Σου λέει ΠΕΘΑΝΕ !! Άνοιξε εναν Λάκκο και πέσε μέσα!!\n",
    "Γιατι? Γιατί τώρα οι ΘΕΑΤΡΙΝΟΙ της Κυβέρνησης παίζουν το ΕΡΓΟ του Κορωνοιού ..Του Μπαμπούλα της Νέας Τάξης ..Τώρα και με νέες στολές Διαστημικές για να θυμίζουν Χολιγουντιανές Ταινίες επιστημονικής Φαντασίας.\n",
    "ΜΕ ΤΟ ΜΈΤΡΟ ΑΥΤΟ ΓΙΝΕΤΑΙ Η ΕΞΟΝΤΩΣΗ ΤΟΥ ΕΛΛΗΝΑ ΠΟΛΙΤΗ ..ΕΧΟΥΝ ΠΟΛΛΟΥΣ ΤΡΟΠΟΥΣ ΟΙ ΣΩΤΗΡΕΣ ΤΗΣ ΝΔ..\n",
    "'''\n",
    "\n",
    "doc = nlp(test)\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with nlp.use_params(optimizer.averages):\n",
    "            nlp.to_disk('../model')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
